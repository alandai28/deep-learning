{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Keras_Cifar-10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeOEBUUFqpxvt5hpSye2Oq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alandai28/deep-learning/blob/master/CNN_Keras_Cifar_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-peJWCjLgvB",
        "colab_type": "text"
      },
      "source": [
        "Cifar-10 的所有圖片被分為 10 個類別 (以 0~9 數字作為 Label 之編碼) :  \n",
        "0 : airplain (飛機)  \n",
        "1 : automobile (汽車)\n",
        "2 : bird (鳥)  \n",
        "3 : cat (貓)  \n",
        "4 : deer (鹿)  \n",
        "5 : dog (狗)  \n",
        "6 : frog (青蛙)  \n",
        "7 : horse (馬)  \n",
        "8 : ship (船)  \n",
        "9 : truck (卡車)  \n",
        "包含 6 萬筆 32*32 低解析度之彩色圖片, 其中 5 萬筆為訓練集; 1 萬筆為測試集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxckS6lALu61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c079caa-3f40-4fe8-d87d-5d18e7f8848b"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "print(X_train.shape) #(50000, 32, 32, 3)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKctGsLBvB9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Normalize Data\n",
        "def normalize(X_train,X_test):\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7)\n",
        "        return X_train, X_test\n",
        "    \n",
        "    \n",
        "## Normalize Training and Testset    \n",
        "x_train, x_test = normalize(X_train, X_test) \n",
        "\n",
        "## OneHot Label 由(None, 1)-(None, 10)\n",
        "one_hot=OneHotEncoder()\n",
        "y_train=one_hot.fit_transform(Y_train).toarray()\n",
        "y_test=one_hot.transform(Y_test).toarray()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6-MOPTXvECZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b972eac-a503-4570-ef36-95e0b187a6fd"
      },
      "source": [
        "classifier=Sequential()\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Conv2D(32,(3,3),input_shape=(32,32,3),activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Conv2D(32,(3,3),activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#flatten\n",
        "classifier.add(Flatten())\n",
        "\n",
        "#FC\n",
        "classifier.add(Dense(100,activation='relu'))\n",
        "classifier.add(Dropout(rate=0.7))\n",
        "classifier.add(Dense(10,activation='softmax'))\n",
        "\n",
        "#超過兩個就要選categorical_crossentrophy\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.fit(x_train,y_train,batch_size=50,epochs=200)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8799 - accuracy: 0.3197\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5499 - accuracy: 0.4357\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3855 - accuracy: 0.5000\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2808 - accuracy: 0.5445\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2023 - accuracy: 0.5767\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1515 - accuracy: 0.5949\n",
            "Epoch 7/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1082 - accuracy: 0.6107\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0691 - accuracy: 0.6275\n",
            "Epoch 9/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0389 - accuracy: 0.6366\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0116 - accuracy: 0.6492\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9896 - accuracy: 0.6533\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9722 - accuracy: 0.6609\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9526 - accuracy: 0.6694\n",
            "Epoch 14/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9330 - accuracy: 0.6728\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9197 - accuracy: 0.6781\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9057 - accuracy: 0.6827\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8895 - accuracy: 0.6881\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8849 - accuracy: 0.6906\n",
            "Epoch 19/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8792 - accuracy: 0.6923\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8626 - accuracy: 0.6984\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8451 - accuracy: 0.7027\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8383 - accuracy: 0.7038\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8398 - accuracy: 0.7043\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8265 - accuracy: 0.7076\n",
            "Epoch 25/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8173 - accuracy: 0.7120\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8139 - accuracy: 0.7100\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8075 - accuracy: 0.7130\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7953 - accuracy: 0.7188\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7894 - accuracy: 0.7184\n",
            "Epoch 30/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7860 - accuracy: 0.7187\n",
            "Epoch 31/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7749 - accuracy: 0.7237\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7756 - accuracy: 0.7249\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7606 - accuracy: 0.7283\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7617 - accuracy: 0.7311\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7553 - accuracy: 0.7313\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7590 - accuracy: 0.7312\n",
            "Epoch 37/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7440 - accuracy: 0.7345\n",
            "Epoch 38/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7486 - accuracy: 0.7342\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7367 - accuracy: 0.7337\n",
            "Epoch 40/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7336 - accuracy: 0.7388\n",
            "Epoch 41/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7349 - accuracy: 0.7362\n",
            "Epoch 42/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7313 - accuracy: 0.7370\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7264 - accuracy: 0.7376\n",
            "Epoch 44/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7172 - accuracy: 0.7427\n",
            "Epoch 45/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7226 - accuracy: 0.7401\n",
            "Epoch 46/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7073 - accuracy: 0.7444\n",
            "Epoch 47/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7037 - accuracy: 0.7456\n",
            "Epoch 48/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7052 - accuracy: 0.7452\n",
            "Epoch 49/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6946 - accuracy: 0.7469\n",
            "Epoch 50/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6955 - accuracy: 0.7492\n",
            "Epoch 51/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6992 - accuracy: 0.7451\n",
            "Epoch 52/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6976 - accuracy: 0.7473\n",
            "Epoch 53/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6920 - accuracy: 0.7498\n",
            "Epoch 54/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6853 - accuracy: 0.7516\n",
            "Epoch 55/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6811 - accuracy: 0.7526\n",
            "Epoch 56/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6789 - accuracy: 0.7543\n",
            "Epoch 57/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6744 - accuracy: 0.7540\n",
            "Epoch 58/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6748 - accuracy: 0.7553\n",
            "Epoch 59/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6708 - accuracy: 0.7554\n",
            "Epoch 60/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6718 - accuracy: 0.7572\n",
            "Epoch 61/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6726 - accuracy: 0.7564\n",
            "Epoch 62/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6625 - accuracy: 0.7584\n",
            "Epoch 63/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6641 - accuracy: 0.7573\n",
            "Epoch 64/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6657 - accuracy: 0.7571\n",
            "Epoch 65/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6634 - accuracy: 0.7586\n",
            "Epoch 66/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6535 - accuracy: 0.7613\n",
            "Epoch 67/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6524 - accuracy: 0.7615\n",
            "Epoch 68/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6515 - accuracy: 0.7611\n",
            "Epoch 69/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6567 - accuracy: 0.7602\n",
            "Epoch 70/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6453 - accuracy: 0.7645\n",
            "Epoch 71/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6459 - accuracy: 0.7632\n",
            "Epoch 72/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6504 - accuracy: 0.7610\n",
            "Epoch 73/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6477 - accuracy: 0.7622\n",
            "Epoch 74/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6464 - accuracy: 0.7622\n",
            "Epoch 75/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6432 - accuracy: 0.7634\n",
            "Epoch 76/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6444 - accuracy: 0.7639\n",
            "Epoch 77/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6381 - accuracy: 0.7628\n",
            "Epoch 78/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6355 - accuracy: 0.7662\n",
            "Epoch 79/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6356 - accuracy: 0.7661\n",
            "Epoch 80/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6361 - accuracy: 0.7651\n",
            "Epoch 81/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6328 - accuracy: 0.7664\n",
            "Epoch 82/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6287 - accuracy: 0.7682\n",
            "Epoch 83/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6264 - accuracy: 0.7670\n",
            "Epoch 84/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6220 - accuracy: 0.7712\n",
            "Epoch 85/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6229 - accuracy: 0.7684\n",
            "Epoch 86/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6215 - accuracy: 0.7720\n",
            "Epoch 87/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6176 - accuracy: 0.7727\n",
            "Epoch 88/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6185 - accuracy: 0.7725\n",
            "Epoch 89/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6198 - accuracy: 0.7724\n",
            "Epoch 90/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6191 - accuracy: 0.7699\n",
            "Epoch 91/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6098 - accuracy: 0.7719\n",
            "Epoch 92/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6167 - accuracy: 0.7715\n",
            "Epoch 93/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6137 - accuracy: 0.7728\n",
            "Epoch 94/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6128 - accuracy: 0.7710\n",
            "Epoch 95/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6097 - accuracy: 0.7721\n",
            "Epoch 96/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6085 - accuracy: 0.7732\n",
            "Epoch 97/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6065 - accuracy: 0.7746\n",
            "Epoch 98/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6056 - accuracy: 0.7756\n",
            "Epoch 99/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5981 - accuracy: 0.7784\n",
            "Epoch 100/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6068 - accuracy: 0.7752\n",
            "Epoch 101/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6043 - accuracy: 0.7758\n",
            "Epoch 102/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5972 - accuracy: 0.7782\n",
            "Epoch 103/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6006 - accuracy: 0.7770\n",
            "Epoch 104/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5991 - accuracy: 0.7778\n",
            "Epoch 105/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5968 - accuracy: 0.7793\n",
            "Epoch 106/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5979 - accuracy: 0.7784\n",
            "Epoch 107/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5928 - accuracy: 0.7791\n",
            "Epoch 108/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5952 - accuracy: 0.7765\n",
            "Epoch 109/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6051 - accuracy: 0.7745\n",
            "Epoch 110/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5951 - accuracy: 0.7790\n",
            "Epoch 111/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5900 - accuracy: 0.7773\n",
            "Epoch 112/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5913 - accuracy: 0.7778\n",
            "Epoch 113/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5902 - accuracy: 0.7801\n",
            "Epoch 114/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5864 - accuracy: 0.7812\n",
            "Epoch 115/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5834 - accuracy: 0.7819\n",
            "Epoch 116/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5825 - accuracy: 0.7819\n",
            "Epoch 117/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5901 - accuracy: 0.7784\n",
            "Epoch 118/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5837 - accuracy: 0.7823\n",
            "Epoch 119/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5802 - accuracy: 0.7845\n",
            "Epoch 120/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5823 - accuracy: 0.7819\n",
            "Epoch 121/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5869 - accuracy: 0.7798\n",
            "Epoch 122/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5761 - accuracy: 0.7854\n",
            "Epoch 123/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5818 - accuracy: 0.7810\n",
            "Epoch 124/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5786 - accuracy: 0.7809\n",
            "Epoch 125/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5783 - accuracy: 0.7808\n",
            "Epoch 126/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5738 - accuracy: 0.7852\n",
            "Epoch 127/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5762 - accuracy: 0.7853\n",
            "Epoch 128/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5802 - accuracy: 0.7823\n",
            "Epoch 129/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5741 - accuracy: 0.7821\n",
            "Epoch 130/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5737 - accuracy: 0.7840\n",
            "Epoch 131/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5723 - accuracy: 0.7840\n",
            "Epoch 132/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5720 - accuracy: 0.7851\n",
            "Epoch 133/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5706 - accuracy: 0.7830\n",
            "Epoch 134/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5756 - accuracy: 0.7822\n",
            "Epoch 135/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5781 - accuracy: 0.7822\n",
            "Epoch 136/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5706 - accuracy: 0.7848\n",
            "Epoch 137/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5635 - accuracy: 0.7870\n",
            "Epoch 138/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5659 - accuracy: 0.7854\n",
            "Epoch 139/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5738 - accuracy: 0.7834\n",
            "Epoch 140/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5727 - accuracy: 0.7846\n",
            "Epoch 141/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5667 - accuracy: 0.7866\n",
            "Epoch 142/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5575 - accuracy: 0.7876\n",
            "Epoch 143/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5656 - accuracy: 0.7856\n",
            "Epoch 144/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5645 - accuracy: 0.7878\n",
            "Epoch 145/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5665 - accuracy: 0.7870\n",
            "Epoch 146/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5600 - accuracy: 0.7876\n",
            "Epoch 147/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5624 - accuracy: 0.7863\n",
            "Epoch 148/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5562 - accuracy: 0.7898\n",
            "Epoch 149/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5628 - accuracy: 0.7879\n",
            "Epoch 150/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5595 - accuracy: 0.7872\n",
            "Epoch 151/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5572 - accuracy: 0.7898\n",
            "Epoch 152/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5594 - accuracy: 0.7888\n",
            "Epoch 153/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5571 - accuracy: 0.7894\n",
            "Epoch 154/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5543 - accuracy: 0.7896\n",
            "Epoch 155/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5563 - accuracy: 0.7884\n",
            "Epoch 156/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5560 - accuracy: 0.7878\n",
            "Epoch 157/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7925\n",
            "Epoch 158/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5488 - accuracy: 0.7925\n",
            "Epoch 159/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5536 - accuracy: 0.7911\n",
            "Epoch 160/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5514 - accuracy: 0.7931\n",
            "Epoch 161/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5538 - accuracy: 0.7909\n",
            "Epoch 162/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5500 - accuracy: 0.7900\n",
            "Epoch 163/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5482 - accuracy: 0.7911\n",
            "Epoch 164/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5492 - accuracy: 0.7918\n",
            "Epoch 165/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5501 - accuracy: 0.7919\n",
            "Epoch 166/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5484 - accuracy: 0.7941\n",
            "Epoch 167/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5482 - accuracy: 0.7919\n",
            "Epoch 168/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5455 - accuracy: 0.7934\n",
            "Epoch 169/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5353 - accuracy: 0.7985\n",
            "Epoch 170/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5452 - accuracy: 0.7917\n",
            "Epoch 171/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5424 - accuracy: 0.7943\n",
            "Epoch 172/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5474 - accuracy: 0.7927\n",
            "Epoch 173/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5491 - accuracy: 0.7921\n",
            "Epoch 174/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5494 - accuracy: 0.7893\n",
            "Epoch 175/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5465 - accuracy: 0.7925\n",
            "Epoch 176/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5456 - accuracy: 0.7941\n",
            "Epoch 177/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5375 - accuracy: 0.7956\n",
            "Epoch 178/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5372 - accuracy: 0.7956\n",
            "Epoch 179/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5472 - accuracy: 0.7907\n",
            "Epoch 180/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5430 - accuracy: 0.7919\n",
            "Epoch 181/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5450 - accuracy: 0.7916\n",
            "Epoch 182/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5399 - accuracy: 0.7940\n",
            "Epoch 183/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5456 - accuracy: 0.7913\n",
            "Epoch 184/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5368 - accuracy: 0.7941\n",
            "Epoch 185/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5403 - accuracy: 0.7931\n",
            "Epoch 186/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5326 - accuracy: 0.7986\n",
            "Epoch 187/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5392 - accuracy: 0.7941\n",
            "Epoch 188/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5471 - accuracy: 0.7915\n",
            "Epoch 189/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5303 - accuracy: 0.7980\n",
            "Epoch 190/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5331 - accuracy: 0.7965\n",
            "Epoch 191/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5343 - accuracy: 0.7982\n",
            "Epoch 192/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5305 - accuracy: 0.7956\n",
            "Epoch 193/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5342 - accuracy: 0.7938\n",
            "Epoch 194/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5344 - accuracy: 0.7949\n",
            "Epoch 195/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5335 - accuracy: 0.7976\n",
            "Epoch 196/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5266 - accuracy: 0.7975\n",
            "Epoch 197/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5361 - accuracy: 0.7955\n",
            "Epoch 198/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5311 - accuracy: 0.7965\n",
            "Epoch 199/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5317 - accuracy: 0.7957\n",
            "Epoch 200/200\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5314 - accuracy: 0.7959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6b033f0550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvLqmr0JvGcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bef64ff7-7f71-4514-9fcc-23d16d7a105c"
      },
      "source": [
        "loss, accuracy = classifier.evaluate(x_test,y_test)\n",
        "print('Total loss on Testiong Set : ',loss)\n",
        "print('Accuracy of Testiong Set : ',accuracy)\n",
        "\n",
        "# Save model\n",
        "classifier.save('./CNN_Cifar10.h5')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.0215 - accuracy: 0.7309\n",
            "Total loss on Testiong Set :  1.021509051322937\n",
            "Accuracy of Testiong Set :  0.73089998960495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc0sBfRDMBJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load Model\n",
        "model = load_model('./CNN_Cifar10.h5')\n",
        "\n",
        "# Display\n",
        "def plot_img(n):\n",
        "    plt.imshow(X_test[n], cmap='gray')\n",
        "    plt.show()\n",
        "    \n",
        "def all_img_predict(model):\n",
        "    print(model.summary())\n",
        "    loss, accuracy = model.evaluate(x_test, y_test)\n",
        "    print('Loss:', loss)\n",
        "    print('Accuracy:', accuracy)\n",
        "    predict = model.predict_classes(x_test)\n",
        "    print(pd.crosstab(Y_test.reshape(-1), predict, rownames=['Label'], colnames=['predict']))\n",
        "\n",
        "def one_img_predict(model, n):\n",
        "    predict = model.predict_classes(x_test)\n",
        "    print('Prediction:', predict[n])\n",
        "    print('Answer:', Y_test[n])\n",
        "    plot_img(n)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u2YMHxnMCL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "f5e1faee-065e-4385-855c-d54690a7e3f4"
      },
      "source": [
        "all_img_predict(model)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_22 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 13, 13, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 100)               115300    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 126,710\n",
            "Trainable params: 126,582\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.0215 - accuracy: 0.7309\n",
            "Loss: 1.021509051322937\n",
            "Accuracy: 0.73089998960495\n",
            "predict    0    1    2    3    4    5    6    7    8    9\n",
            "Label                                                    \n",
            "0        760   18   57   24   12    4    6   17   63   39\n",
            "1         17  840   10    7    2    5   12    3   21   83\n",
            "2         60    4  586   73   75   70   80   32   11    9\n",
            "3          9    6   71  543   60  190   65   33   13   10\n",
            "4         19    1   60   73  696   32   51   58    9    1\n",
            "5          4    4   40  177   48  669   19   27    8    4\n",
            "6          2    6   42   64   35   20  820    2    7    2\n",
            "7         11    3   29   39   70   86    6  746    2    8\n",
            "8         68   26   14   29    5    9    6    4  823   16\n",
            "9         31   69    3   26    3    7    6    6   23  826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hyXfCtyMEGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ec45c907-e4d2-43f7-c1be-ece1b9ffef8b"
      },
      "source": [
        "one_img_predict(model, 5413)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: 5\n",
            "Answer: [3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}